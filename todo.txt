❌ - nevyreseno
❗ - docasne reseni (warning)
❓ - zvazit jine provedeni
🚧 - in progress
✅ - vyreseno

=========

Minor:
- ❌ matrix pretty print
- ✅ zmenit raw pointery na smart pointery
- ✅ vyresit warningy od Clangu
- ✅ pridat const metody pro Matrix.h
- ❌ auto& vs auto&&
- ❌ T& vs T&&
- ❌ CustomLayer
- ❌ Bezparametricke konstruktory layeru?
- ❌ Overridnout operator "<<" u tridy Graph -> vypise strukturu grafu
- ❌ Prejmenovat tridu Graph na tridu Network
- ❌ Predelat nektere public metody (apply elementwise, hadamard) na staticke metody
- ❗ metoda RandomInitialization() uvnitr Matrix.h je definovana pouze pro double typy
    - kdyz se zavola s jinym typem, tak se provede implicitni konverze
- ❌ const verze metod pro funkce
- ❌ predelat Apply u aktivacnich funkci, aby braly jako parametr matici a ne skalar
- ❌ smazat Vector tridu
- ❌ udelat Input layer nedostupny z klient kodu
=========

Major:
- ❌❌❌ Podpora pro vice nez 2D matice ---> implementace tensoru ---> predelani vsech layeru + layer interface + vsech funkci                                            
    ---> templaty s promennym poctem parametru
- ✅ Dummy input layer (ten, co je tam implicitne vzdy) provede operaci: "input * weights + b". Coz by asi prave tento input dummy layer delat nemel
    - Nejspis by mel proste jen zkopirovat vstup a nic jineho. Tohle pusobi tak, ze o tom user nevi
    - Navrh reseni: trida "DummyInputLayer" jako potomek "IdentityLayer"?
- ✅ nejspis oddelat ApplyFunctionElementWise a radeji primo u funkci mit verze, co berou matice
    - nebo radeji aby ApplyFunctionElementWise brala pointer na funkci
    - vyreseno tak, ze jsem oddelal cele ApplyFunctionElementWise a dal pristup k begin a end iteratorum pro data_
- ❌ move constructors
- ❌ move assignment operators
- ✅ pridat namespace pro funkce
- ✅ vector trida jako potomek Matrix
- 🚧 graph class
    - ✅ sablonove?  
    - ✅ expected output
    - ❌ train()
    - ❌ test()
    - ✅ forward vypocet v grafu
    - 🚧 backprop vypocet v grafu
        - 🚧 gradient descent
        - ❌ stochastic gradient descent
- 🚧 Loss interface
    - ✅ loss funkce
    - ✅ gradient vuci predicted output
- 🚧 layer interface
    - ✅ layer input
    - ✅ layer output
    - ✅ activation function
    - ❌ derivace aktivaci
    - ✅ weights
    - ❌ bias
    - ✅ output size
    - ✅ activations
    - ❌❌ Projit inicializaci matic v LayerInterface, mozna se provadi nejake operaci navic (reshapovani, etc)
        ---> - ❓ dovolit operatoru = u Matrix class, dosazeni matice jinych rozmeru do jine matice?
- ✅ jednotlive vrstvy
    - ✅ uvnitr graph class
    - ✅ stejny typ jako graf
- 🚧 activation funkce interface
    - ✅ interface
    - ✅ konkretni aktivacni funkce
    - 🚧 derivace aktivacnich funkci
(- ❌ postavit computational graf)